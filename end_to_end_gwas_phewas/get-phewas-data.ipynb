{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract phenotype data from ICD10 for PheWAS analysis\n",
    "\n",
    "## As-Is Software Disclaimer\n",
    "\n",
    "This notebook is delivered \"As-Is\". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.\n",
    "\n",
    "[MIT License](https://github.com/dnanexus/UKB_RAP/blob/main/LICENSE) applies to this notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyterlab app details (launch configuration)\n",
    "\n",
    "Recommended configuration\n",
    "- Runtime: ~20 min\n",
    "- Cluster configuration: `Single Node`\n",
    "- Recommended instance: `mem2_ssd1_v2_x32`\n",
    "- Cost: ~£0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "|Library |License|\n",
    "|:------------- |:-------------|\n",
    "|[pandas](https://pandas.pydata.org/) |[BSD-3](https://github.com/pandas-dev/pandas/blob/main/LICENSE)|\n",
    "|[numpy](https://numpy.org/) |[BSD-3](https://github.com/numpy/numpy/blob/main/LICENSE.txt)|\n",
    "|[bgenix](https://enkre.net/cgi-bin/code/bgen/doc/trunk/doc/wiki/bgenix.md) | [Boost Software License (MIT-like)](https://enkre.net/cgi-bin/code/bgen/file?name=LICENSE_1_0.txt&ci=trunk)|\n",
    "|[PLINK2](https://www.cog-genomics.org/plink/2.0/) |[GPL](https://github.com/chrchang/plink-ng/blob/master/2.0/COPYING)|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook:\n",
    "- Retrieves ICD10 codes for samples\n",
    "- Create phenotype table in long format for subsequent PheWAS analysis\n",
    "- Cleans covariates file\n",
    "- Extracts genetic data, one file per variant\n",
    "- Uploads data to UKB RAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the install commands if you are comfortable with the library license and want to install and run the parts notebook that depend on the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "%%bash\n",
    "# Install PLINK2\n",
    "#cd /opt/notebooks\n",
    "#wget https://s3.amazonaws.com/plink2-assets/alpha3/plink2_linux_avx2_20220814.zip\n",
    "#unzip -o plink2_linux_avx2_20220814.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./plink2 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "%%bash\n",
    "# Install bgenix\n",
    "#cd /opt/notebooks\n",
    "#wget http://code.enkre.net/bgen/tarball/release/bgen.tgz\n",
    "#tar xvfz bgen.tgz > /dev/null\n",
    "#cd bgen.tgz/\n",
    "#./waf configure \n",
    "#./waf \n",
    "#./build/test/unit/test_bgen\n",
    "#./build/apps/bgenix -g example/example.16bits.bgen –list\n",
    "#cd /opt/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dxpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset description and select entity containing phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically discover dispensed dataset ID and load the dataset\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\"\n",
    ")\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get project ID\n",
    "project_id = dxpy.find_one_project()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\":\").join([project_id, dispensed_dataset_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `-ddd` parameter will extract 3 dictionary files associated with the dataset.\n",
    "\n",
    "The 3 dictionary files that are returned include:\n",
    "1. `entity_dictionary` that contains the different tables resources that are available. The table we’re most interested in tends to be the participant table that contains the information about each participant.\n",
    "2. `data_dictionary` that contains the different field names that we might want to include in our dataset.\n",
    "3. `coding_dictionary` that contains a lookup for the values for some of the field names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The following cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\"dx\", \"extract_dataset\", dataset, \"-ddd\", \"--delimiter\", \",\"]\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify fields ID to retrieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `eid` - Participant's ID\n",
    "- `41270` - [Diagnoses - ICD10](https://biobank.ndph.ox.ac.uk/ukb/field.cgi?id=41270)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data\n",
    "\n",
    "In this section we:\n",
    "1. Use the `data_dictionary.csv` table to filter the list of field names and select ones of interest (i.e. 'eid' and 'p41270').\n",
    "2. Next we concatenate the field names with entity name (i.e. 'participant')\n",
    "3. Finally, we use this list of field names joined with entity names (i.e. 'participant.eid') to query for a dataset with only those fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_ids = [\"41270\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_csv = glob.glob(os.path.join(path, \"*.data_dictionary.csv\"))[0]\n",
    "data_dict_df = pd.read_csv(data_dict_csv)\n",
    "data_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The UKB participant tables have the following naming convention for the fields (or columns): \"p<field id>_i<instance id>_a<array id>\"\n",
    "# This function is used to grab all field names (e.g. \"p<field_id>_iYYY_aZZZ\") given a list of field IDs and return string to pass into\n",
    "# extract_dataset\n",
    "def fields_for_id(field_id):\n",
    "    field_names = [\"eid\"]\n",
    "    for _id in field_id:\n",
    "        select_field_names = list(\n",
    "            data_dict_df[\n",
    "                data_dict_df.name.str.match(r\"^p{}(_i\\d+)?(_a\\d+)?$\".format(_id))\n",
    "            ].name.values\n",
    "        )\n",
    "        field_names += select_field_names\n",
    "\n",
    "    field_names = [f\"participant.{f}\" for f in field_names]\n",
    "    return \",\".join(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = fields_for_id(field_ids)\n",
    "field_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# Note: This cell can only be run once. Otherwise, you'll need to delete the existing data tables in order to re-run\n",
    "# Note: There is no space separating the different fields\n",
    "cmd = [\n",
    "    \"dx\",\n",
    "    \"extract_dataset\",\n",
    "    dataset,\n",
    "    \"--fields\",\n",
    "    field_names,\n",
    "    \"--delimiter\",\n",
    "    \",\",\n",
    "    \"--output\",\n",
    "    \"pheno_dictionary.csv\",\n",
    "]\n",
    "subprocess.check_call(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_dict_csv = \"pheno_dictionary.csv\"\n",
    "pheno = pd.read_csv(pheno_dict_csv)\n",
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column headers\n",
    "pheno = pheno.rename(columns=lambda x: re.sub(\"participant.\", \"\", x))\n",
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create phenotype table in PheWAS format\n",
    "\n",
    "Each row is containing one phenotype (ICD 10 diagnosis) for one participant. Therefore, when participant has multiple diagnoses, participants eid will appear multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the values in the p41270 column from a string representation of a list to an actual list\n",
    "# using ast.literal_eval()\n",
    "pheno = pheno.set_index(\"eid\").dropna()\n",
    "pheno[\"p41270\"] = pheno[\"p41270\"].apply(lambda x: ast.literal_eval(x))\n",
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_long_all = pheno.explode(\"p41270\").reset_index()\n",
    "pheno_long_all[\"count\"] = 1\n",
    "pheno_long_all[\"vocabulary_id\"] = \"ICD10\"\n",
    "pheno_long_all.rename({\"eid\": \"id\", \"p41270\": \"code\"}, axis=1, inplace=True)\n",
    "pheno_long_all = pheno_long_all[[\"id\", \"vocabulary_id\", \"code\", \"count\"]]\n",
    "pheno_long_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_long_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save phenotype table as CSV file and upload it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_long_all.to_csv(\"pheno_icd10_long.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dx upload pheno_icd10_long.csv --path /Data/PheWAS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get covariate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dx download -f /Data/ischemia_df.phe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(\"ischemia_df.phe\", sep='\\t')\n",
    "pheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno[['FID']].to_csv('eids_to_keep.txt', index=False, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dx upload eids_to_keep.txt --path /Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = pheno.loc[:, [col for col in pheno.columns if col not in ['FID', 'ischemia_cc', 'hdl_cholesterol', 'ldl_cholesterol', 'hypertension']]]\n",
    "covars.rename(columns={'IID': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars.to_csv('covariates.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dx upload covariates.txt --path /Data/PheWAS/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get genetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download results of LD clumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dx download -f /Data/LD_clump/plink_all_ld_clumped_ld_clumped.clumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_results = pd.read_csv('plink_all_ld_clumped_ld_clumped.clumped', delim_whitespace=True)\n",
    "ld_results.sort_values(by='P').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create symlink for imputed data\n",
    "DIR='/mnt/project/Bulk/Imputation/Imputation*from*genotype*(GEL)'\n",
    "ln -sf $DIR /opt/notebooks/imputed\n",
    "DIR2=/mnt/project/Bulk-DRL/GEL_imputed_sample_files_fixed/\n",
    "ln -sf $DIR2 /opt/notebooks/samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each varinat in LD table, extract genotypes and create PLINK raw file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('phewas_geno_data'):\n",
    "    shutil.rmtree('phewas_geno_data')\n",
    "\n",
    "os.mkdir('phewas_geno_data')\n",
    "\n",
    "for rsid in ld_results['SNP'].values:\n",
    "    chromosome = ld_results[ld_results['SNP'] == rsid]['CHR'].values[0]\n",
    "    #rsid = 'rs10455872'\n",
    "    print(f'rsID: {rsid}, chromosome: {chromosome}')\n",
    "    new_bgen_name = f'phewas_geno_data/{rsid}.bgen'\n",
    "    plink_output_prefix = f'phewas_geno_data/plink_{rsid}'\n",
    "    with open(new_bgen_name, 'wb') as new_bgen:\n",
    "        print(f'Extract significant rsIDs')\n",
    "        subprocess.check_call(['/opt/notebooks/bgen.tgz/build/apps/bgenix', '-g', f'imputed/ukb21008_c{chromosome}_b0_v1.bgen', \n",
    "                        '-incl-rsids', rsid], stdout=new_bgen, stderr=subprocess.PIPE)\n",
    "        print(f'Make PLINK files')\n",
    "        subprocess.check_call(['./plink2', '--bgen', new_bgen_name, 'ref-first', '--sample', \n",
    "                           f'samples/ukb21008_c{chromosome}_b0_v1.sample', '--rm-dup', 'force-first', '--out', plink_output_prefix,\n",
    "                           '--keep-fam', 'eids_to_keep.txt', '--export',  'A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open each raw PLINK file and rename header to be in PheWAS format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('phewas_geno_rsid'):\n",
    "    shutil.rmtree('phewas_geno_rsid')\n",
    "\n",
    "os.mkdir('phewas_geno_rsid')\n",
    "\n",
    "for file in glob.glob('phewas_geno_data/*.raw'):\n",
    "    print(file.split('/')[1])\n",
    "    dosage = pd.read_csv(file, sep='\\t')\n",
    "    dosage = dosage.iloc[:, [0,-1]]\n",
    "    dosage.rename(columns={dosage.columns[0]: 'id', dosage.columns[1]: dosage.columns[1].split('_')[0]}, inplace = True)\n",
    "    dosage.to_csv(f'phewas_geno_rsid/{dosage.columns[1]}.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to UKB RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dx upload -r phewas_geno_rsid/ --path /Data/PheWAS/phewas_geno_rsid/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output files\n",
    "\n",
    "- Phenome data in long format containing ICD 10 codes per participant (`pheno_icd10_long.csv`)\n",
    "- Covariates file (`covariates.txt`)\n",
    "- List of participants EIDs to include in the analysis (`eids_to_keep.txt`)\n",
    "- Table for each index variant in LD clumping containing 2 columns: participant ID and rsID genotyping results (`<rsid>.raw`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
